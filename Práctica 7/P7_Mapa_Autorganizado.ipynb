{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a9b55537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f803b49f",
   "metadata": {},
   "source": [
    "### Clases Neurona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "95f4b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neurona(object):\n",
    "    def __init__(self, f=0, c=0, dim=0):\n",
    "        self.c = c\n",
    "        self.f = f\n",
    "        self.dim = dim\n",
    "        \n",
    "        # Inicializa los pesos aleatoriamente entre [-0.5, 0.5]\n",
    "        self.w = normalize(0.5 - np.random.rand(dim).reshape(1,-1))\n",
    "        \n",
    "        # self.label_winner = []\n",
    "            \n",
    "    def predict(self, inputs):\n",
    "        # Calcula la salida de una neurona ante una o más entradas. \"inputs\" puede ser un vector o una matriz 2D\n",
    "        return inputs @ self.w.T\n",
    "    \n",
    "    def fit(self, input, alfa=1):\n",
    "        # ajusta los pesos de una neurona (w) para aproximarlos a una entrada (input)\n",
    "        self.w = normalize(self.w + (alfa*input))\n",
    "            \n",
    "    def neuron_labeling(self, inputs, target):\n",
    "        # etiquetado por neuronas. Se le pasa la lista de entradas y la etiqueta (target) de cada una de esas muestras.\n",
    "        # Devuelve la etiqueta de la ganadora\n",
    "        Y = inputs @ self.w.T\n",
    "        self.label = target[np.argmax(Y)]\n",
    "        return self.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c9bc26",
   "metadata": {},
   "source": [
    "### Clase SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7b073a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class som():\n",
    "    \n",
    "    def __init__(self, filas=1, columnas=1, dim=1):\n",
    "        self.lista = []\n",
    "        self.filas = filas\n",
    "        self.columnas = columnas\n",
    "        self.dim = dim\n",
    "        \n",
    "        # Considera que un mapa rectangular es una lista de objetos \"neurona\", que viene localizado por sus atributos \"fila\" y \"columna\"\n",
    "        for fila in range(self.filas):\n",
    "            for columna in range(self.columnas):\n",
    "                self.lista.append(neurona(f=fila, c=columna, dim=dim))\n",
    "                \n",
    "    def fit(self, inputs, max_epochs=1, init_radious=0, init_alfa=1):\n",
    "        # método similar a otros algoritmo de ML. Recibe las entradas, el radio inicial, el factor de apendizaje inicial,\n",
    "        # el máximo de épocas y devuelve los pesos ajustados\n",
    "        self.radious = init_radious\n",
    "        self.alfa = init_alfa\n",
    "        t = 0\n",
    "        P = inputs.shape[0]\n",
    "        for epoch in range(max_epochs):\n",
    "            for x in inputs:\n",
    "                self.alfa = init_alfa/(1.0 + float(t/P))\n",
    "                i_gana, y_gana = -1, float('-inf')\n",
    "                for i in range(self.filas*self.columnas):\n",
    "                    y_predict = self.lista[i].predict(x.reshape(1,-1))\n",
    "                    if y_predict > y_gana:\n",
    "                        y_gana = y_predict\n",
    "                        i_gana = i\n",
    "                f_gana = int(i_gana / self.columnas)\n",
    "                c_gana = i_gana % self.columnas\n",
    "                \n",
    "                # Conjunto de vecinas para un radious\n",
    "                for f in range(f_gana - self.radious, f_gana + self.radious+1):\n",
    "                    if f < 0:\n",
    "                        row = self.filas + f\n",
    "                    else:\n",
    "                        if f > self.filas-1:\n",
    "                            row = f % self.filas\n",
    "                        else:\n",
    "                            row = f\n",
    "\n",
    "                    for c in range(c_gana - self.radious, c_gana + self.radious+1):\n",
    "                        if c < 0:\n",
    "                            column = self.columnas + c \n",
    "                        else:\n",
    "                            if c > self.columnas-1:\n",
    "                                column = c % self.columnas\n",
    "                            else:\n",
    "                                column = c\n",
    "                        self.lista[(row*self.columnas) + column].fit(x.reshape(1,-1), alfa=self.alfa)\n",
    "                t += 1\n",
    "                if (t%1000) == 0:\n",
    "                    print(t, self.radious, \"  \", end='')\n",
    "            if self.radious > 0:\n",
    "                self.radious -= 1\n",
    "                            \n",
    "    def neuron_labeling(self, inputs, target):\n",
    "        # recorre la lista de neuronas y va llamanado a su metodo de etiquetado para cada neurona\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in range(self.filas*self.columnas):\n",
    "            # print(X.shape, self.target.shape)\n",
    "            self.labels.append(self.lista[i].neuron_labeling(inputs, target))\n",
    "            # print(self.lista[i].labeling(X, target=y_deseada, etiquetado='neurona'))\n",
    " \n",
    "    def predict(self, inputs):\n",
    "        # recorre la lista de neuronas y calcula la salida de un conjunto de muestras\n",
    "        # util para usar la salida del som como entrada a otrso sistemas\n",
    "        output_list = []\n",
    "        for x in inputs:\n",
    "            for i in range(self.filas*self.columnas):\n",
    "                output_list.append(self.lista[i].predict(x.reshape(1,-1)))\n",
    "        return np.array(output_list).reshape(inputs.shape[0], -1)    \n",
    "    \n",
    "    def label_predict(self, inputs):\n",
    "        # clasificación de muestras con el etiquetado de cada neurona hecho previamente\n",
    "        label_list = []\n",
    "        for x in inputs:\n",
    "            label_list.append(self.labels[np.argmax(self.predict(x.reshape(1,-1)))])\n",
    "        return np.array(label_list).reshape(inputs.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc7954",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c6935a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.data.shape, mnist.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9cb0f266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0           0.0       0.0       0.0       0.0       0.0  \n",
       "1           0.0       0.0       0.0       0.0       0.0  \n",
       "2           0.0       0.0       0.0       0.0       0.0  \n",
       "3           0.0       0.0       0.0       0.0       0.0  \n",
       "4           0.0       0.0       0.0       0.0       0.0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "69995       0.0       0.0       0.0       0.0       0.0  \n",
       "69996       0.0       0.0       0.0       0.0       0.0  \n",
       "69997       0.0       0.0       0.0       0.0       0.0  \n",
       "69998       0.0       0.0       0.0       0.0       0.0  \n",
       "69999       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[70000 rows x 784 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mnist.data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9f909b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5\n",
       "1        0\n",
       "2        4\n",
       "3        1\n",
       "4        9\n",
       "        ..\n",
       "69995    2\n",
       "69996    3\n",
       "69997    4\n",
       "69998    5\n",
       "69999    6\n",
       "Name: class, Length: 70000, dtype: category\n",
       "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = mnist.target\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf1c6b",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "84171d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizacion datos\n",
    "scalar = StandardScaler()\n",
    "datos_scd = scalar.fit_transform(data)\n",
    "datos_scd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6eab4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data & Test data\n",
    "train_data, test_data, train_label, test_label = train_test_split(datos_scd, label, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d8ca6e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46900, 784)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6a04e3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23100, 784)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f79117",
   "metadata": {},
   "source": [
    "### Creación SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a0ab1908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 9   2000 9   3000 9   4000 9   5000 9   6000 9   7000 9   8000 9   9000 9   10000 9   11000 9   12000 9   13000 9   14000 9   15000 9   16000 9   17000 9   18000 9   19000 9   20000 9   21000 9   22000 9   23000 9   24000 9   25000 9   26000 9   27000 9   28000 9   29000 9   30000 9   31000 9   32000 9   33000 9   34000 9   35000 9   36000 9   37000 9   38000 9   39000 9   40000 9   41000 9   42000 9   43000 9   44000 9   45000 9   46000 9   47000 8   48000 8   49000 8   50000 8   51000 8   52000 8   53000 8   54000 8   55000 8   56000 8   57000 8   58000 8   59000 8   60000 8   61000 8   62000 8   63000 8   64000 8   65000 8   66000 8   67000 8   68000 8   69000 8   70000 8   71000 8   72000 8   73000 8   74000 8   75000 8   76000 8   77000 8   78000 8   79000 8   80000 8   81000 8   82000 8   83000 8   84000 8   85000 8   86000 8   87000 8   88000 8   89000 8   90000 8   91000 8   92000 8   93000 8   94000 7   95000 7   96000 7   97000 7   98000 7   99000 7   100000 7   101000 7   102000 7   103000 7   104000 7   105000 7   106000 7   107000 7   108000 7   109000 7   110000 7   111000 7   112000 7   113000 7   114000 7   115000 7   116000 7   117000 7   118000 7   119000 7   120000 7   121000 7   122000 7   123000 7   124000 7   125000 7   126000 7   127000 7   128000 7   129000 7   130000 7   131000 7   132000 7   133000 7   134000 7   135000 7   136000 7   137000 7   138000 7   139000 7   140000 7   141000 6   142000 6   143000 6   144000 6   145000 6   146000 6   147000 6   148000 6   149000 6   150000 6   151000 6   152000 6   153000 6   154000 6   155000 6   156000 6   157000 6   158000 6   159000 6   160000 6   161000 6   162000 6   163000 6   164000 6   165000 6   166000 6   167000 6   168000 6   169000 6   170000 6   171000 6   172000 6   173000 6   174000 6   175000 6   176000 6   177000 6   178000 6   179000 6   180000 6   181000 6   182000 6   183000 6   184000 6   185000 6   186000 6   187000 6   188000 5   189000 5   190000 5   191000 5   192000 5   193000 5   194000 5   195000 5   196000 5   197000 5   198000 5   199000 5   200000 5   201000 5   202000 5   203000 5   204000 5   205000 5   206000 5   207000 5   208000 5   209000 5   210000 5   211000 5   212000 5   213000 5   214000 5   215000 5   216000 5   217000 5   218000 5   219000 5   220000 5   221000 5   222000 5   223000 5   224000 5   225000 5   226000 5   227000 5   228000 5   229000 5   230000 5   231000 5   232000 5   233000 5   234000 5   235000 4   236000 4   237000 4   238000 4   239000 4   240000 4   241000 4   242000 4   243000 4   244000 4   245000 4   246000 4   247000 4   248000 4   249000 4   250000 4   251000 4   252000 4   253000 4   254000 4   255000 4   256000 4   257000 4   258000 4   259000 4   260000 4   261000 4   262000 4   263000 4   264000 4   265000 4   266000 4   267000 4   268000 4   269000 4   270000 4   271000 4   272000 4   273000 4   274000 4   275000 4   276000 4   277000 4   278000 4   279000 4   280000 4   281000 4   282000 3   283000 3   284000 3   285000 3   286000 3   287000 3   288000 3   289000 3   290000 3   291000 3   292000 3   293000 3   294000 3   295000 3   296000 3   297000 3   298000 3   299000 3   300000 3   301000 3   302000 3   303000 3   304000 3   305000 3   306000 3   307000 3   308000 3   309000 3   310000 3   311000 3   312000 3   313000 3   314000 3   315000 3   316000 3   317000 3   318000 3   319000 3   320000 3   321000 3   322000 3   323000 3   324000 3   325000 3   326000 3   327000 3   328000 3   329000 2   330000 2   331000 2   332000 2   333000 2   334000 2   335000 2   336000 2   337000 2   338000 2   339000 2   340000 2   341000 2   342000 2   343000 2   344000 2   345000 2   346000 2   347000 2   348000 2   349000 2   350000 2   351000 2   352000 2   353000 2   354000 2   355000 2   356000 2   357000 2   358000 2   359000 2   360000 2   361000 2   362000 2   363000 2   364000 2   365000 2   366000 2   367000 2   368000 2   369000 2   370000 2   371000 2   372000 2   373000 2   374000 2   375000 2   376000 1   377000 1   378000 1   379000 1   380000 1   381000 1   382000 1   383000 1   384000 1   385000 1   386000 1   387000 1   388000 1   389000 1   390000 1   391000 1   392000 1   393000 1   394000 1   395000 1   396000 1   397000 1   398000 1   399000 1   400000 1   401000 1   402000 1   403000 1   404000 1   405000 1   406000 1   407000 1   408000 1   409000 1   410000 1   411000 1   412000 1   413000 1   414000 1   415000 1   416000 1   417000 1   418000 1   419000 1   420000 1   421000 1   422000 1   423000 0   424000 0   425000 0   426000 0   427000 0   428000 0   429000 0   430000 0   431000 0   432000 0   433000 0   434000 0   435000 0   436000 0   437000 0   438000 0   439000 0   440000 0   441000 0   442000 0   443000 0   444000 0   445000 0   446000 0   447000 0   448000 0   449000 0   450000 0   451000 0   452000 0   453000 0   454000 0   455000 0   456000 0   457000 0   458000 0   459000 0   460000 0   461000 0   462000 0   463000 0   464000 0   465000 0   466000 0   467000 0   468000 0   469000 0   470000 0   471000 0   472000 0   473000 0   474000 0   475000 0   476000 0   477000 0   478000 0   479000 0   480000 0   481000 0   482000 0   483000 0   484000 0   485000 0   486000 0   487000 0   488000 0   489000 0   490000 0   491000 0   492000 0   493000 0   494000 0   495000 0   496000 0   497000 0   498000 0   499000 0   500000 0   501000 0   502000 0   503000 0   504000 0   505000 0   506000 0   507000 0   508000 0   509000 0   510000 0   511000 0   512000 0   513000 0   514000 0   515000 0   516000 0   517000 0   518000 0   519000 0   520000 0   521000 0   522000 0   523000 0   524000 0   525000 0   526000 0   527000 0   528000 0   529000 0   530000 0   531000 0   532000 0   533000 0   534000 0   535000 0   536000 0   537000 0   538000 0   539000 0   540000 0   541000 0   542000 0   543000 0   544000 0   545000 0   546000 0   547000 0   548000 0   549000 0   550000 0   551000 0   552000 0   553000 0   554000 0   555000 0   556000 0   557000 0   558000 0   559000 0   560000 0   561000 0   562000 0   563000 0   564000 0   565000 0   566000 0   567000 0   568000 0   569000 0   570000 0   571000 0   572000 0   573000 0   574000 0   575000 0   576000 0   577000 0   578000 0   579000 0   580000 0   581000 0   582000 0   583000 0   584000 0   585000 0   586000 0   587000 0   588000 0   589000 0   590000 0   591000 0   592000 0   593000 0   594000 0   595000 0   596000 0   597000 0   598000 0   599000 0   600000 0   601000 0   602000 0   603000 0   604000 0   605000 0   606000 0   607000 0   608000 0   609000 0   610000 0   611000 0   612000 0   613000 0   614000 0   615000 0   616000 0   617000 0   618000 0   619000 0   620000 0   621000 0   622000 0   623000 0   624000 0   625000 0   626000 0   627000 0   628000 0   629000 0   630000 0   631000 0   632000 0   633000 0   634000 0   635000 0   636000 0   637000 0   638000 0   639000 0   640000 0   641000 0   642000 0   643000 0   644000 0   645000 0   646000 0   647000 0   648000 0   649000 0   650000 0   651000 0   652000 0   653000 0   654000 0   655000 0   656000 0   657000 0   658000 0   659000 0   660000 0   661000 0   662000 0   663000 0   664000 0   665000 0   666000 0   667000 0   668000 0   669000 0   670000 0   671000 0   672000 0   673000 0   674000 0   675000 0   676000 0   677000 0   678000 0   679000 0   680000 0   681000 0   682000 0   683000 0   684000 0   685000 0   686000 0   687000 0   688000 0   689000 0   690000 0   691000 0   692000 0   693000 0   694000 0   695000 0   696000 0   697000 0   698000 0   699000 0   700000 0   701000 0   702000 0   703000 0   704000 0   705000 0   706000 0   707000 0   708000 0   709000 0   710000 0   711000 0   712000 0   713000 0   714000 0   715000 0   716000 0   717000 0   718000 0   719000 0   720000 0   721000 0   722000 0   723000 0   724000 0   725000 0   726000 0   727000 0   728000 0   729000 0   730000 0   731000 0   732000 0   733000 0   734000 0   735000 0   736000 0   737000 0   738000 0   739000 0   740000 0   741000 0   742000 0   743000 0   744000 0   745000 0   746000 0   747000 0   748000 0   749000 0   750000 0   751000 0   752000 0   753000 0   754000 0   755000 0   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756000 0   757000 0   758000 0   759000 0   760000 0   761000 0   762000 0   763000 0   764000 0   765000 0   766000 0   767000 0   768000 0   769000 0   770000 0   771000 0   772000 0   773000 0   774000 0   775000 0   776000 0   777000 0   778000 0   779000 0   780000 0   781000 0   782000 0   783000 0   784000 0   785000 0   786000 0   787000 0   788000 0   789000 0   790000 0   791000 0   792000 0   793000 0   794000 0   795000 0   796000 0   797000 0   798000 0   799000 0   800000 0   801000 0   802000 0   803000 0   804000 0   805000 0   806000 0   807000 0   808000 0   809000 0   810000 0   811000 0   812000 0   813000 0   814000 0   815000 0   816000 0   817000 0   818000 0   819000 0   820000 0   821000 0   822000 0   823000 0   824000 0   825000 0   826000 0   827000 0   828000 0   829000 0   830000 0   831000 0   832000 0   833000 0   834000 0   835000 0   836000 0   837000 0   838000 0   839000 0   840000 0   841000 0   842000 0   843000 0   844000 0   845000 0   846000 0   847000 0   848000 0   849000 0   850000 0   851000 0   852000 0   853000 0   854000 0   855000 0   856000 0   857000 0   858000 0   859000 0   860000 0   861000 0   862000 0   863000 0   864000 0   865000 0   866000 0   867000 0   868000 0   869000 0   870000 0   871000 0   872000 0   873000 0   874000 0   875000 0   876000 0   877000 0   878000 0   879000 0   880000 0   881000 0   882000 0   883000 0   884000 0   885000 0   886000 0   887000 0   888000 0   889000 0   890000 0   891000 0   892000 0   893000 0   894000 0   895000 0   896000 0   897000 0   898000 0   899000 0   900000 0   901000 0   902000 0   903000 0   904000 0   905000 0   906000 0   907000 0   908000 0   909000 0   910000 0   911000 0   912000 0   913000 0   914000 0   915000 0   916000 0   917000 0   918000 0   919000 0   920000 0   921000 0   922000 0   923000 0   924000 0   925000 0   926000 0   927000 0   928000 0   929000 0   930000 0   931000 0   932000 0   933000 0   934000 0   935000 0   936000 0   937000 0   938000 0   "
     ]
    }
   ],
   "source": [
    "# Creacion de la red neuronal SOM\n",
    "mapa = som(15,9, train_data.shape[1])\n",
    "\n",
    "# Entrenamos la red neuronal\n",
    "mapa.fit(train_data, max_epochs=20, init_radious=9, init_alfa=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d439fa54",
   "metadata": {},
   "source": [
    "#### Etiquetado por neuronas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696a89b",
   "metadata": {},
   "source": [
    "Procedemos a etiquetar las neuronas que conforman la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "192d764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa.neuron_labeling(train_data, train_label.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6669bdfd",
   "metadata": {},
   "source": [
    "Obtenemos los labels de cada neurona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "132c6680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23100, 1)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_labels = mapa.label_predict(test_data)\n",
    "neuron_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76eee34",
   "metadata": {},
   "source": [
    "Porcentaje de acierto utilizando etiquetado por neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "743a4721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6894805194805195"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_label, neuron_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a9578",
   "metadata": {},
   "source": [
    "Obtenemos también las labels de las neuronas a partir de las muestras de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "69df65c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46900, 1)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_labels_train = mapa.label_predict(train_data)\n",
    "neuron_labels_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c15a23",
   "metadata": {},
   "source": [
    "### Con la salida del SOM, construimos un conjunto de aprendizaje y uno de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51777d",
   "metadata": {},
   "source": [
    "Recorremos la lista de neuronas del mapa y calculamos la salida de un conjunto de muestras mediante el metodo **predict()**.\n",
    "\n",
    "Util para usar la salida del SOM como entrada a otros sistemas, en nuestro caso, hacia un **MLP (135x60x10)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f707d",
   "metadata": {},
   "source": [
    "#### Conjunto de Aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "840c366f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.77884805,   3.35548404,  -4.20348889, ...,  -2.06757109,\n",
       "         -4.10180719,   1.91384614],\n",
       "       [  0.97736482,  -2.85324449,  -4.58843191, ...,  -3.63068857,\n",
       "         -3.84131166,  -1.10199706],\n",
       "       [  0.46562347, -10.31075157,   1.9125644 , ...,  -9.88953808,\n",
       "         -4.22236495,  -8.4505119 ],\n",
       "       ...,\n",
       "       [ -2.84295508,   2.33214141,  -2.33341898, ...,   0.78573895,\n",
       "          4.03545879,  -0.70006905],\n",
       "       [  3.95969068,   4.85215316,  -1.88094791, ...,   1.14477172,\n",
       "         -0.96085618,   5.01590182],\n",
       "       [ -4.29069942,  -2.62592409,  -1.63535628, ...,   1.23919531,\n",
       "          4.94683404,  -0.64804869]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = mapa.predict(train_data)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b09f0e4",
   "metadata": {},
   "source": [
    "Obtenemos un conjunto de aprendizaje con 135 columnas *(15 filas * 9 columnas)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2642d5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46900, 135)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca6b43",
   "metadata": {},
   "source": [
    "#### Conjunto de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "181e932d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26716462, -1.16621821, -1.51097821, ..., -1.16953037,\n",
       "         0.33224332, -1.48017279],\n",
       "       [-0.19533257, -1.33039494, -0.38224758, ...,  1.53238102,\n",
       "        -1.32505378,  4.20364452],\n",
       "       [ 3.14460384,  4.10009752, -3.67776665, ...,  0.43988146,\n",
       "        -3.30925697,  3.95866123],\n",
       "       ...,\n",
       "       [ 1.24763835,  0.28271729, -3.77575677, ..., -2.3557496 ,\n",
       "        -2.68690506,  2.77967877],\n",
       "       [-0.94001418,  0.8170134 , -2.90112635, ..., -0.21170029,\n",
       "        -1.55346173,  8.00656603],\n",
       "       [ 1.79205457,  2.2203157 , -2.71833431, ...,  0.51110464,\n",
       "        -1.44685203,  5.27386259]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = mapa.predict(test_data)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fb76c148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23100, 135)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971366e6",
   "metadata": {},
   "source": [
    "### Creacion MLP (135x60x10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412cd7c",
   "metadata": {},
   "source": [
    "Como se nos indica, debemos crear un MLP con una capa de entrada formada por 135 neuronas, una capa oculta de 60 neuronas y una capa de salida de 10 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "189060f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2a55df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(60,), activation='relu', solver='adam', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4d3896ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46900, 135), (46900, 1))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, neuron_labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0e3009a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jhon\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Jhon\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(60,), random_state=1)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train, neuron_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "54dc9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "04b6453f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23100,)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bf54b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7006060606060606"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_label, y_predict) ## tiene que dar sobre 0.967"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
